{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = '{}/code'.format(os.path.abspath(os.path.join('..')))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp1_sorcerers_stone' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp2_chamber_of_secrets' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp3_prisioner_of_azkaban' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp4_globet_of_fire' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp5_order_of_the_phoenix' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp6_half_blood_prince' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp7_deathly_hallows' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp_places_list' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp_characters_list' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp_classes_list' to 'data/' folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'hp_spells_list' to 'data/' folder.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from variables import *\n",
    "\n",
    "!mkdir ../data\n",
    "utils.download_files(BOOKS)\n",
    "utils.download_files(EXTRAS)\n",
    "utils.extract_html_table(SPELLS, na_values=['-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "books, spells, extras = {}, {}, {}\n",
    "\n",
    "for f in sorted(glob.glob(os.path.join('../data', '*.txt'))):\n",
    "    with open(f, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        books[os.path.splitext(os.path.basename(f))[0]] = file.read().replace('\\n', ' ')\n",
    "        \n",
    "for f in sorted(glob.glob(os.path.join('../data', '*.csv'))):\n",
    "    extras[os.path.splitext(os.path.basename(f))[0]] = pd.read_csv(f, header=None)[0].tolist()\n",
    "    \n",
    "spells = pd.read_json(glob.glob(os.path.join('../data', '*.json'))[0], lines=True)\n",
    "spells = spells[~spells['Resulting Effect'].str.contains('game')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Incantation                  Resulting Effect        Type\n0            Aberto                     Opens objects       Charm\n1             Accio                 Summons an object       Charm\n2          Age Line  Hides things from younger people  Enchanment\n3         Aguamenti           Shoots water from wand.       Charm\n4  Alarte Ascendare     Shoots things high in the air       Spell\n5         Alohomora              Opens locked objects       Charm\n6           Anapneo       Clears the targetâ€™s airway.       Spell\n7      Anteoculatia      Turns head hair into antlers         Hex\n8     Anti-Cheating        Prevents Cheating on Exams       Spell\n9         Aparecium             Reveals invisible ink       Spell"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spells.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hp_characters_list', 'hp_classes_list', 'hp_places_list'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extras.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hp1_sorcerers_stone', 'hp2_chamber_of_secrets', 'hp3_prisioner_of_azkaban', 'hp4_globet_of_fire', 'hp5_order_of_the_phoenix', 'hp6_half_blood_prince', 'hp7_deathly_hallows'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone   CHAPTER ONE   THE BOY WHO LIVED   Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.   Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large musta\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['hp1_sorcerers_stone'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/luigi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/luigi/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "punc = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def normalize_text(text):\n",
    "    tokens = word_tokenize(text.translate(punc))\n",
    "    stopwords = sw.words('english')\n",
    "    content = [w.lower() for w in tokens if w.lower() not in stopwords]\n",
    "    return content\n",
    "\n",
    "def get_bigrams(text):\n",
    "    tokens = word_tokenize(text.translate(punc))\n",
    "    return ngrams(tokens, 2)\n",
    "\n",
    "def get_trigrams(text):\n",
    "    tokens = word_tokenize(text.translate(punc))\n",
    "    return ngrams(tokens, 3)\n",
    "\n",
    "def get_wordcount(text):\n",
    "    tokens = word_tokenize(text.translate(punc))\n",
    "    return len(tokens)\n",
    "\n",
    "def get_unique_wordcount(text):\n",
    "    tokens = word_tokenize(text.translate(punc))\n",
    "    return len(set(tokens))\n",
    "    \n",
    "def get_unique_punct_count(text):\n",
    "    punct = [c for c in text if c in string.punctuation]\n",
    "    return len(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "books_clean = {}\n",
    "wordcount = 0\n",
    "\n",
    "for book in books:\n",
    "    books_clean[book] = normalize_text(books[book])\n",
    "    books_clean['{}_bigrams'.format(book)] = get_bigrams(books[book])\n",
    "    books_clean['{}_trigrams'.format(book)] = get_trigrams(books[book])\n",
    "    books_clean['{}_wordcount'.format(book)] = get_wordcount(books[book])\n",
    "    books_clean['{}_unique_wordcount'.format(book)] = get_unique_wordcount(books[book])\n",
    "    books_clean['{}_unique_punct_count'.format(book)] = get_unique_punct_count(books[book])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "hp-data-cleaning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
